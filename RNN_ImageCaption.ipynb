{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI COMP5623_CW2_24/04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu1Z4mMrnjMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from re import search\n",
        "from collections import Counter\n",
        "import string\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from nltk import tokenize\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os.path\n",
        "from os import path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGG0j4UF79aY",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeA0Ef9ylhBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"a guy snowboarding down a hill\"\n",
        "\"a skier in a ski suit is skiing downhill near a fence\"\n",
        "\"a skier races down the mountain\"\n",
        "\"a slalom skier moving quickly downhill\"\n",
        "\"competing skier going down the course leaning to make a sharp turn\"\n",
        "\n",
        "\"a guy snowboard down a hill\"\n",
        "\"a skier in a ski suit be ski downhill , near a fence \"\n",
        "\"a skier race down a mountain \"\n",
        "\"a slalom skier move quick downhill \"\n",
        "\"compete skier go down a course lean to make a sharp turn\"\n",
        "\n",
        "to_be_stemmed = (\"a skier in a ski suit is skiing downhill near a fence\").split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t7vY6-L8JmQ",
        "colab_type": "code",
        "outputId": "e88a3b55-e09d-402e-fb20-358f89153849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "ps =PorterStemmer()\n",
        "for w in to_be_stemmed:\n",
        "    rootWord=ps.stem(w)\n",
        "    print(f\"Porter stemmer performed on '{w}' produces:\", rootWord)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Porter stemmer performed on 'a' produces: a\n",
            "Porter stemmer performed on 'skier' produces: skier\n",
            "Porter stemmer performed on 'in' produces: in\n",
            "Porter stemmer performed on 'a' produces: a\n",
            "Porter stemmer performed on 'ski' produces: ski\n",
            "Porter stemmer performed on 'suit' produces: suit\n",
            "Porter stemmer performed on 'is' produces: is\n",
            "Porter stemmer performed on 'skiing' produces: ski\n",
            "Porter stemmer performed on 'downhill' produces: downhil\n",
            "Porter stemmer performed on 'near' produces: near\n",
            "Porter stemmer performed on 'a' produces: a\n",
            "Porter stemmer performed on 'fence' produces: fenc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cxFUashy9o6",
        "colab_type": "code",
        "outputId": "76ce8d49-41ef-49c7-8ab0-fb6e7cd4e08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "ls =LancasterStemmer()\n",
        "for w in to_be_stemmed:\n",
        "    rootWord=ls.stem(w)\n",
        "    print(f\"Lancaster stemmer performed on '{w}' produces:\", rootWord)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lancaster stemmer performed on 'a' produces: a\n",
            "Lancaster stemmer performed on 'skier' produces: ski\n",
            "Lancaster stemmer performed on 'in' produces: in\n",
            "Lancaster stemmer performed on 'a' produces: a\n",
            "Lancaster stemmer performed on 'ski' produces: ski\n",
            "Lancaster stemmer performed on 'suit' produces: suit\n",
            "Lancaster stemmer performed on 'is' produces: is\n",
            "Lancaster stemmer performed on 'skiing' produces: ski\n",
            "Lancaster stemmer performed on 'downhill' produces: downhil\n",
            "Lancaster stemmer performed on 'near' produces: near\n",
            "Lancaster stemmer performed on 'a' produces: a\n",
            "Lancaster stemmer performed on 'fence' produces: fent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a31sFIyrHaXl",
        "colab_type": "text"
      },
      "source": [
        "# COMP5623 Coursework on Image Caption Generation\n",
        "\n",
        "Starter code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81kdnnwJvTFx",
        "colab_type": "text"
      },
      "source": [
        "## Text preparation \n",
        "\n",
        "We need to build a vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXpWOFqFOXcc",
        "colab_type": "code",
        "outputId": "36c6a050-ed28-49a7-9fbb-c7520cbd3a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Mounted Drive if using Colab; otherwise, your local path \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root = \"/content/gdrive/My Drive/Flickr8k/\" # <--- replace this with your root data directory\n",
        "caption_dir = root + \"captions/\"                       # <--- replace these too\n",
        "image_dir = root + \"images/\"                           # <---\n",
        "\n",
        "\n",
        "token_file = \"Flickr8k.token.txt\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9AkORttFoF_",
        "colab_type": "text"
      },
      "source": [
        "A helper function to read in our ground truth text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHC0y7zaOXq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_lines(filepath):\n",
        "    \"\"\" Open the ground truth captions into memory, line by line. \"\"\"\n",
        "    file = open(filepath, 'r')\n",
        "    lines = []\n",
        "\n",
        "    while True: \n",
        "        # Get next line from file until there's no more\n",
        "        line = file.readline() \n",
        "        if not line: \n",
        "            break\n",
        "        lines.append(line.strip())\n",
        "    file.close() \n",
        "    return lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D86cJx2yv81K",
        "colab_type": "text"
      },
      "source": [
        "You can read all the ground truth captions (5 per image), into memory as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m-snsM2XHuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = read_lines(caption_dir + token_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXPl8K4agcYO",
        "colab_type": "code",
        "outputId": "9f6b15b4-d43a-4529-9202-015e0b9e0cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "lines[:7]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1000268201_693b08cb0e.jpg#0\\tA child in a pink dress is climbing up a set of stairs in an entry way .',\n",
              " '1000268201_693b08cb0e.jpg#1\\tA girl going into a wooden building .',\n",
              " '1000268201_693b08cb0e.jpg#2\\tA little girl climbing into a wooden playhouse .',\n",
              " '1000268201_693b08cb0e.jpg#3\\tA little girl climbing the stairs to her playhouse .',\n",
              " '1000268201_693b08cb0e.jpg#4\\tA little girl in a pink dress going into a wooden cabin .',\n",
              " '1001773457_577c3a7d70.jpg#0\\tA black dog and a spotted dog are fighting',\n",
              " '1001773457_577c3a7d70.jpg#1\\tA black dog and a tri-colored dog playing with each other on the road .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oksUJjLPwApA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Simple vocabulary wrapper which maps every unique word to an integer ID. \"\"\"\n",
        "    def __init__(self):\n",
        "        # Intially, set both the IDs and words to empty dictionaries.\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        # If the word does not already exist in the dictionary, add it\n",
        "        if not word in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            # Increment the ID for the next word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __call__(self, word):\n",
        "        # If we try to access a word in the dictionary which does not exist, return the <unk> id\n",
        "        if not word in self.word2idx:\n",
        "            return self.word2idx['<unk>']\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEQtthpXwEoY",
        "colab_type": "text"
      },
      "source": [
        "Extract all the words from ```lines```, and create a list of them in a variable ```words```, for example:\n",
        "\n",
        "```words = [\"a\", \"an\", \"the\", \"cat\"... ]```\n",
        "\n",
        "No need to worry about duplicates.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9M3UWSAwAsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "vocabbin = []\n",
        "count = 0\n",
        "for line in lines:\n",
        "  words = line.lower().split()\n",
        "  words.pop(0)\n",
        "  for word in words:\n",
        "    if not any(l in word for l in string.punctuation):\n",
        "      vocabbin.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHBMe-ATwLIQ",
        "colab_type": "text"
      },
      "source": [
        "Build the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctwErx_ZwAzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a vocab instance\n",
        "vocab = Vocabulary()\n",
        "\n",
        "# Add the token words first\n",
        "vocab.add_word('<pad>')\n",
        "vocab.add_word('<start>')\n",
        "vocab.add_word('<end>')\n",
        "vocab.add_word('<unk>')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L3jfvKHeMr_6",
        "colab": {}
      },
      "source": [
        "vocab_sorted = vocabbin\n",
        "vocab_sorted.sort()\n",
        "w_count = 0\n",
        "count = 0\n",
        "\n",
        "for w in vocab_sorted:\n",
        "  if count > 1:\n",
        "    count += -1\n",
        "    continue\n",
        "  \n",
        "  count = vocab_sorted.count(w)\n",
        "  if (count > 3):\n",
        "    w_count += 1\n",
        "    vocab.add_word(w)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6csDgtkRpM5q",
        "colab_type": "code",
        "outputId": "bcdc33f9-e203-458a-8e7a-30cbd1b49aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(vocab))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB30f4wYwSvg",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and loaders for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raEOHrpnbbKY",
        "colab_type": "text"
      },
      "source": [
        "Keeping the same order, concatenate all the cleaned words from each caption into a string again, and add them all to a list of strings ```cleaned_captions```. Store all the image ids in a list ```image_ids```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGGnaDIRbZUs",
        "colab_type": "code",
        "outputId": "407f61ba-5c81-46ce-9f91-c1831b3d076f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_ids = []\n",
        "for line in lines:\n",
        "  words = line.lower().split()\n",
        "  image_ids.append(words[0].split('.')[0])\n",
        "print(len(image_ids))\n",
        "\n",
        "words=[]\n",
        "cleaned_captions = []\n",
        "for line in lines:\n",
        "  words = line.lower().split()\n",
        "  words.pop(0)\n",
        "  for word in words:\n",
        "    words2 = []\n",
        "    if any(l in word for l in string.punctuation):\n",
        "      words.remove(word)\n",
        "  cleaned_captions.append(' '.join(words))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_FbII1VwVSg",
        "colab_type": "text"
      },
      "source": [
        "The dataframe for the image paths and captions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYQz4T3mwA2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = {\n",
        "    'image_id': image_ids,\n",
        "    'path': [image_dir + image_id + \".jpg\" for image_id in image_ids],\n",
        "    'caption': cleaned_captions\n",
        "}\n",
        "\n",
        "data_df = pd.DataFrame(data, columns=['image_id', 'path', 'caption'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POB7UiJLwYsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete these row indexes from dataFrame\n",
        "\n",
        "indexNames = data_df[ data_df['image_id'] == \"2258277193_586949ec62\" ].index\n",
        "data_df.drop(indexNames , inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNLQ0K-_weJy",
        "colab_type": "text"
      },
      "source": [
        "This is the Flickr8k class for the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqf2_F6YwakD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flickr8k(Dataset):\n",
        "    \"\"\" Flickr8k custom dataset compatible with torch.utils.data.DataLoader. \"\"\"\n",
        "    \n",
        "    def __init__(self, df, vocab, transform=None):\n",
        "        \"\"\" Set the path for images, captions and vocabulary wrapper.\n",
        "        \n",
        "        Args:\n",
        "            df: df containing image paths and captions.\n",
        "            vocab: vocabulary wrapper.\n",
        "            transform: image transformer.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.vocab = vocab\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Returns one data pair (image and caption). \"\"\"\n",
        "\n",
        "        vocab = self.vocab\n",
        "\n",
        "        caption = self.df['caption'][index]\n",
        "        img_id = self.df['image_id'][index]\n",
        "        path = self.df['path'][index]\n",
        "\n",
        "        image = Image.open(open(path, 'rb'))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert caption (string) to word ids.\n",
        "        tokens = caption.split()\n",
        "        caption = []\n",
        "        # Build the Tensor version of the caption, with token words\n",
        "        caption.append(vocab('<start>'))\n",
        "        caption.extend([vocab(token) for token in tokens])\n",
        "        caption.append(vocab('<end>'))\n",
        "        target = torch.Tensor(caption)\n",
        "        return image, target, img_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCTtUpKfu7MC",
        "colab_type": "code",
        "outputId": "4da1a12d-05c4-4a28-e863-9235635c2c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_df[\"caption\"][1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a girl going into a wooden building'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vkld_4CwkPO",
        "colab_type": "text"
      },
      "source": [
        "We need to overwrite the default PyTorch ```collate_fn()``` because our ground truth captions are sequential data of varying lengths. The default ```collate_fn()``` does not support merging the captions with padding.\n",
        "\n",
        "You can read more about it here: https://pytorch.org/docs/stable/data.html#dataloader-collate-fn. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5YmKr9ewkqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def caption_collate_fn(data):\n",
        "    \"\"\" Creates mini-batch tensors from the list of tuples (image, caption).\n",
        "    Args:\n",
        "        data: list of tuple (image, caption). \n",
        "            - image: torch tensor of shape (3, 256, 256).\n",
        "            - caption: torch tensor of shape (?); variable length.\n",
        "    Returns:\n",
        "        images: torch tensor of shape (batch_size, 3, 256, 256).\n",
        "        targets: torch tensor of shape (batch_size, padded_length).\n",
        "        lengths: list; valid length for each padded caption.\n",
        "    \"\"\"\n",
        "    # Sort a data list by caption length from longest to shortest.\n",
        "    data.sort(key=lambda x: len(x[1]), reverse=True)\n",
        "    images, captions, ids = zip(*data)\n",
        "\n",
        "    # Merge images (from tuple of 3D tensor to 4D tensor).\n",
        "    images = torch.stack(images, 0)\n",
        "\n",
        "    # Merge captions (from tuple of 1D tensor to 2D tensor).\n",
        "    lengths = [len(cap) for cap in captions]\n",
        "    targets = torch.zeros(len(captions), max(lengths)).long()\n",
        "    for i, cap in enumerate(captions):\n",
        "        end = lengths[i]\n",
        "        targets[i, :end] = cap[:end]        \n",
        "    return images, targets, lengths, ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6VDx2O5FSiM",
        "colab_type": "text"
      },
      "source": [
        "Now we define the data transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpRbVk6BFTGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Crop size matches the input dimensions expected by the pre-trained ResNet\n",
        "data_transform = transforms.Compose([ \n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),  # Why do we choose 224 x 224?\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),   # Using ImageNet norms\n",
        "                         (0.229, 0.224, 0.225))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgS9OpZ7FaAj",
        "colab_type": "text"
      },
      "source": [
        "Initialising the datasets. The only twist is that every image has 5 ground truth captions, so each image appears five times in the dataframe. We don't want an image to appear in more than one set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnTvR684GGVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unit_size = 5\n",
        "\n",
        "train_split = 0.95 # Defines the ratio of train/test data.\n",
        "\n",
        "# We didn't shuffle the dataframe yet so this works\n",
        "train_size = unit_size * round(len(data_df)*train_split / unit_size)\n",
        "\n",
        "dataset_train = Flickr8k(\n",
        "    df=data_df[:train_size].reset_index(drop=True),\n",
        "    vocab=vocab,\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "dataset_test = Flickr8k(\n",
        "    df=data_df[(train_size):].reset_index(drop=True),\n",
        "    vocab=vocab,\n",
        "    transform=data_transform,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWuWg72dGOq9",
        "colab_type": "text"
      },
      "source": [
        "Write the dataloaders ```train_loader``` and ```test_loader``` - explicitly replacing the collate_fn:\n",
        "\n",
        "```train_loader = torch.utils.data.DataLoader(\n",
        "  ...,\n",
        "  collate_fn=caption_collate_fn\n",
        ")```\n",
        "\n",
        "Set train batch size to 128 and be sure to set ```shuffle=True```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXlf8lt5TF0N",
        "colab_type": "text"
      },
      "source": [
        "## Encoder and decoder models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls8lyXA2GTC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderCNN(nn.Module):\n",
        "    def __init__(self, embed_size):\n",
        "        \"\"\"Load the pretrained ResNet-152 and replace top fc layer.\"\"\"\n",
        "        super(EncoderCNN, self).__init__()\n",
        "        resnet = models.resnet152(pretrained=True) # Pre-trained on ImageNet by default\n",
        "        layers = list(resnet.children())[:-1]      # Keep all layers except the last one\n",
        "        # Unpack the layers and create a new Sequential\n",
        "        self.resnet = nn.Sequential(*layers)\n",
        "        \n",
        "        # We want a specific output size, which is the size of our embedding, so\n",
        "        # we feed our extracted features from the last fc layer (dimensions 1 x 1000)\n",
        "        # into a Linear layer to resize\n",
        "        self.linear = nn.Linear(resnet.fc.in_features, embed_size)\n",
        "        \n",
        "        # Batch normalisation helps to speed up training\n",
        "        self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)\n",
        "        \n",
        "    def forward(self, images):\n",
        "        \"\"\"Extract feature vectors from input images.\"\"\"\n",
        "        \n",
        "        # Complete graph here. Remember to put the ResNet layer in a with torch.no_grad() block\n",
        "        with torch.no_grad():\n",
        "            features = self.resnet(images)\n",
        "        features = features.reshape(features.size(0), -1)\n",
        "        features = self.bn(self.linear(features))\n",
        "        return features\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers, max_seq_length=20):\n",
        "        \"\"\"Set the hyper-parameters and build the layers.\"\"\"\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        \n",
        "        # What is an embedding layer?\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        # Define this layer (one at a time)\n",
        "        # self.lstm / self.rnn\n",
        "        #self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.rnn = nn.RNN(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        \n",
        "    def forward(self, features, captions, lengths):\n",
        "        \"\"\"Decode image feature vectors and generates captions.\"\"\"\n",
        "        embeddings = self.embed(captions)\n",
        "        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
        "        # What is \"packing\" a padded sequence?\n",
        "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True) \n",
        "        #hiddens, _ = self.lstm(packed) # Replace with self.rnn when using RNN\n",
        "        hiddens, _ = self.rnn(packed) # Replace with self.rnn when using RNN\n",
        "        outputs = self.linear(hiddens[0])\n",
        "        return outputs\n",
        "    \n",
        "    def sample(self, features, states=None):\n",
        "        \"\"\"Generate captions for given image features using greedy search.\"\"\"\n",
        "        sampled_ids = []\n",
        "        inputs = features.unsqueeze(1)\n",
        "        for i in range(self.max_seq_length):\n",
        "            #hiddens, states = self.lstm(inputs, states)  \n",
        "            hiddens, states = self.rnn(inputs, states)        # hiddens: (batch_size, 1, hidden_size)\n",
        "            outputs = self.linear(hiddens.squeeze(1))            # outputs:  (batch_size, vocab_size)\n",
        "            _, predicted = outputs.max(1)                        # predicted: (batch_size)\n",
        "            sampled_ids.append(predicted)\n",
        "            inputs = self.embed(predicted)                       # inputs: (batch_size, embed_size)\n",
        "            inputs = inputs.unsqueeze(1)                         # inputs: (batch_size, 1, embed_size)\n",
        "        sampled_ids = torch.stack(sampled_ids, 1)                # sampled_ids: (batch_size, max_seq_length)\n",
        "        return sampled_ids\n",
        "\n",
        "class DecoderLSTM(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers, max_seq_length=20):\n",
        "        \"\"\"Set the hyper-parameters and build the layers.\"\"\"\n",
        "        super(DecoderLSTM, self).__init__()\n",
        "        \n",
        "        # What is an embedding layer?\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        # Define this layer (one at a time)\n",
        "        # self.lstm / self.rnn\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        \n",
        "    def forward(self, features, captions, lengths):\n",
        "        \"\"\"Decode image feature vectors and generates captions.\"\"\"\n",
        "        embeddings = self.embed(captions)\n",
        "        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
        "        # What is \"packing\" a padded sequence?\n",
        "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True) \n",
        "        hiddens, _ = self.lstm(packed) # Replace with self.rnn when using RNN\n",
        "        outputs = self.linear(hiddens[0])\n",
        "        return outputs\n",
        "    \n",
        "    def sample(self, features, states=None):\n",
        "        \"\"\"Generate captions for given image features using greedy search.\"\"\"\n",
        "        sampled_ids = []\n",
        "        inputs = features.unsqueeze(1)\n",
        "        for i in range(self.max_seq_length):\n",
        "            hiddens, states = self.lstm(inputs, states)  \n",
        "            outputs = self.linear(hiddens.squeeze(1))            # outputs:  (batch_size, vocab_size)\n",
        "            _, predicted = outputs.max(1)                        # predicted: (batch_size)\n",
        "            sampled_ids.append(predicted)\n",
        "            inputs = self.embed(predicted)                       # inputs: (batch_size, embed_size)\n",
        "            inputs = inputs.unsqueeze(1)                         # inputs: (batch_size, 1, embed_size)\n",
        "        sampled_ids = torch.stack(sampled_ids, 1)                # sampled_ids: (batch_size, max_seq_length)\n",
        "        return sampled_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zWuz2Vmks4QC",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader( dataset_train, batch_size=128, shuffle=True, sampler=None,\n",
        "           batch_sampler=None, num_workers=0, collate_fn=caption_collate_fn ,\n",
        "           pin_memory=False, drop_last=False, timeout=0,\n",
        "           worker_init_fn=None)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader( dataset_test, batch_size=128, shuffle=True, sampler=None,\n",
        "           batch_sampler=None, num_workers=0, collate_fn=caption_collate_fn ,\n",
        "           pin_memory=False, drop_last=False, timeout=0,\n",
        "           worker_init_fn=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9-qtkkMTrtB",
        "colab_type": "code",
        "outputId": "8d14ba0c-7671-4011-ced0-4bfb8731eb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhecFOMRUgpe",
        "colab_type": "text"
      },
      "source": [
        "Set training parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fd2-IX2Uer3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "log_step = 10\n",
        "save_step = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlIwF6P8UgB4",
        "colab_type": "text"
      },
      "source": [
        "## Initialisation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxwDUlR2Uy7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INITIALISATION\n",
        "encoderLSTM = EncoderCNN(embed_size).to(device)\n",
        "decoderLSTM = DecoderLSTM(embed_size, hidden_size, len(vocab), num_layers).to(device)\n",
        "\n",
        "encoderRNN = EncoderCNN(embed_size).to(device)\n",
        "decoderRNN = DecoderRNN(embed_size, hidden_size, len(vocab), num_layers).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKCUulQVHLIm",
        "colab_type": "text"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5iB6zvpePTt",
        "colab_type": "code",
        "outputId": "6e011be5-0d0f-4054-f1d5-052261af7359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "encoderLSTM.load_state_dict(torch.load(\"/content/gdrive/My Drive/Flickr8k/encoder-5LSTM.ckpt\"))\n",
        "decoderLSTM.load_state_dict(torch.load(\"/content/gdrive/My Drive/Flickr8k/decoder-5LSTM.ckpt\"))\n",
        "encoderLSTM.eval()\n",
        "decoderLSTM.eval()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-75a32005b2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoderLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/Flickr8k/encoder-5LSTM.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdecoderLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/Flickr8k/decoder-5LSTM.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoderLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdecoderLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4HK5KooHK2m",
        "colab_type": "code",
        "outputId": "4f5a6c24-365f-44bb-ede5-b4fec3515233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "encoderRNN.load_state_dict(torch.load(\"/content/gdrive/My Drive/Flickr8k/encoder-5RNN.ckpt\"))\n",
        "decoderRNN.load_state_dict(torch.load(\"/content/gdrive/My Drive/Flickr8k/decoder-5RNN.ckpt\"))\n",
        "encoderRNN.eval()\n",
        "decoderRNN.eval()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderRNN(\n",
              "  (embed): Embedding(3389, 256)\n",
              "  (rnn): RNN(256, 512, batch_first=True)\n",
              "  (linear): Linear(in_features=512, out_features=3389, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOXwuWRqYg7f",
        "colab_type": "text"
      },
      "source": [
        "## Select Encoder/Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mj-6mMPXe1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM\n",
        "\n",
        "encoder = encoderLSTM\n",
        "decoder = decoderLSTM\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimisation will be on the parameters of BOTH the enocder and decoder,\n",
        "# but excluding the ResNet parameters, only the new added layers.\n",
        "params = list(\n",
        "    decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters()\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(params, lr=learning_rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsN2Rg5VXf4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN\n",
        "\n",
        "encoder = encoderRNN\n",
        "decoder = decoderRNN\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimisation will be on the parameters of BOTH the enocder and decoder,\n",
        "# but excluding the ResNet parameters, only the new added layers.\n",
        "params = list(\n",
        "    decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters()\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(params, lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS4oN21vNKu7",
        "colab_type": "text"
      },
      "source": [
        "The loop to train the model. Feel free to put this in a function if you prefer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiFLZyvThpbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variables for test data\n",
        "images = torch.tensor([], dtype=torch.float32)\n",
        "#images = []\n",
        "captions = []\n",
        "image_ids = []\n",
        "\n",
        "for i, (imgs, caps, _, ids) in enumerate(test_loader):\n",
        "  #Images\n",
        "  #for image in imgs:\n",
        "  #  images.append(image)\n",
        "  #images.extend(imgs)\n",
        "  images = torch.cat((images, imgs.cpu()))\n",
        "  \n",
        "  # Captions\n",
        "  for sentence in caps:\n",
        "    ref = []\n",
        "    for wordtok in sentence.tolist():\n",
        "      word = vocab.idx2word[wordtok]\n",
        "      if word == '<start>' or word == '<pad>':\n",
        "        continue\n",
        "      if word == '<end>':\n",
        "        break\n",
        "      ref.append(word)\n",
        "    captions.append(' '.join(ref))\n",
        "  \n",
        "  # IDs\n",
        "  image_ids.extend(ids)\n",
        "\n",
        "\n",
        "# IDs of the same image\n",
        "indexes = []\n",
        "for image_id in set(image_ids):\n",
        "  image_indexes = []\n",
        "  for i in range(len(image_ids)): \n",
        "    if image_ids[i] == image_id:\n",
        "      image_indexes.append(i)\n",
        "  indexes.append(image_indexes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8_qNJ1DtXL3",
        "colab_type": "code",
        "outputId": "6277ccd5-2aa0-40c5-90b1-94212aa66cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(images))\n",
        "images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2025, 3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwJoMO0PpN67",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkcoa_0MA2tb",
        "colab_type": "code",
        "outputId": "760e5a8c-8ce4-4dd4-ce46-6f81c9c93735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "bleu_scores = 0\n",
        "bleu_scores_1 = 0\n",
        "bleu_scores_2 = 0\n",
        "bleu_scores_3 = 0\n",
        "bleu_scores_4 = 0\n",
        "bleu_scores_5 = 0\n",
        "bleu_scores_med = 0\n",
        "bleu_scores_short = 0\n",
        "bleu_scores_long = 0\n",
        "bleu_scores_med_count = 0\n",
        "bleu_scores_short_count = 0\n",
        "bleu_scores_long_count = 0\n",
        "\n",
        "sentence_len = []\n",
        "sentence_lens = []\n",
        "its = indexes\n",
        "\n",
        "for image_ids in its:\n",
        "  first_id = image_ids[0]\n",
        "\n",
        "  image = images[(first_id):(first_id+1)].to(device)\n",
        "  feature = encoder(image)\n",
        "  sampled_ids = decoder.sample(feature)\n",
        "  sampled_ids = sampled_ids[0].cpu().numpy()\n",
        "\n",
        "  sampled_caption = []\n",
        "  for word_id in sampled_ids:\n",
        "    word = vocab.idx2word[word_id]\n",
        "    if word == '<start>' or word == '<pad>':\n",
        "      continue\n",
        "    if word == '<end>':\n",
        "      break\n",
        "    sampled_caption.append(word)\n",
        "\n",
        "\n",
        "  references = []\n",
        "  for idx in image_ids:\n",
        "    references.append(captions[idx])\n",
        "\n",
        "\n",
        "  wordcount = len(sampled_caption)-2\n",
        "  sentence_len.append(wordcount)\n",
        "  sentence = ' '.join(sampled_caption)\n",
        "  \n",
        "  if wordcount < 8:\n",
        "    bleu_scores_short += sentence_bleu(references, sentence, smoothing_function = SmoothingFunction().method4)\n",
        "    bleu_scores_short_count += 1\n",
        "  \n",
        "  if wordcount >= 8 and wordcount <= 12:\n",
        "    bleu_scores_med += sentence_bleu(references, sentence, smoothing_function = SmoothingFunction().method4)\n",
        "    bleu_scores_med_count += 1\n",
        "\n",
        "  if wordcount > 12:\n",
        "    bleu_scores_long += sentence_bleu(references, sentence, smoothing_function = SmoothingFunction().method4)\n",
        "    bleu_scores_long_count += 1\n",
        "\n",
        "  #print(sentence)\n",
        "  #print('Cumulative 1-gram: %f' % sentence_bleu(references, sentence, weights=(1, 0, 0, 0),smoothing_function = SmoothingFunction().method4))\n",
        "  #print('Cumulative 2-gram: %f' % sentence_bleu(references, sentence, weights=(0.5, 0.5, 0, 0),smoothing_function = SmoothingFunction().method4))\n",
        "  #print('Cumulative 3-gram: %f' % sentence_bleu(references, sentence, weights=(0.33, 0.33, 0.33, 0),smoothing_function = SmoothingFunction().method4))\n",
        "  #print('Cumulative 4-gram: %f' % sentence_bleu(references, sentence, weights=(0.25, 0.25, 0.25, 0.25),smoothing_function = SmoothingFunction().method4))\n",
        "  #print('Cumulative 5-gram: %f' % sentence_bleu(references, sentence, weights=(0.2, 0.2, 0.2, 0.2,0.2), smoothing_function = SmoothingFunction().method4))\n",
        "\n",
        "  #print(sentence_bleu(references, sentence, smoothing_function = SmoothingFunction().method4))\n",
        "  bleu_scores += sentence_bleu(references, sentence, smoothing_function = SmoothingFunction().method4)\n",
        "\n",
        "  bleu_scores_1 += sentence_bleu(references, sentence, weights=(1, 0, 0, 0),smoothing_function = SmoothingFunction().method4)\n",
        "  bleu_scores_2 += sentence_bleu(references, sentence, weights=(0.5, 0.5, 0, 0),smoothing_function = SmoothingFunction().method4)\n",
        "  bleu_scores_3 += sentence_bleu(references, sentence, weights=(0.33, 0.33, 0.33, 0),smoothing_function = SmoothingFunction().method4)\n",
        "  bleu_scores_4 += sentence_bleu(references, sentence, weights=(0.25, 0.25, 0.25, 0.25),smoothing_function = SmoothingFunction().method4)\n",
        "  bleu_scores_5 += sentence_bleu(references, sentence, weights=(0.2, 0.2, 0.2, 0.2,0.2), smoothing_function = SmoothingFunction().method4)\n",
        "  \n",
        "  image = images[first_id].cpu()\n",
        "  #plt.figure()\n",
        "  #plt.imshow((torchvision.utils.make_grid(image, nrow=1, normalize=True )).permute(1, 2, 0))  \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "    \n",
        "   #Print out the image and the generated caption\n",
        "\n",
        "#print(\"BLEU: \",sentence_bleu(references, sentence, smoothing_function = SmoothingFunction().method4))\n",
        "\n",
        "print(\"Average 1-gram bleu score: \",bleu_scores_1/len(its))\n",
        "print(\"Average 2-gram bleu score: \",bleu_scores_2/len(its))\n",
        "print(\"Average 3-gram bleu score: \",bleu_scores_3/len(its))\n",
        "print(\"Average 4-gram bleu score: \",bleu_scores_4/len(its))\n",
        "print(\"Average 5-gram bleu score: \",bleu_scores_5/len(its))\n",
        "print(\"Number of sentences: \", len(its))\n",
        "\n",
        "print(\"Average 4-gram bleu score of short sentences: \",bleu_scores_short/bleu_scores_short_count)\n",
        "print(\"Number of short sentences: \", bleu_scores_short_count)\n",
        "\n",
        "print(\"Average 4-gram bleu score of medium sentences: \",bleu_scores_med/bleu_scores_med_count)\n",
        "print(\"Number of medium sentences: \",bleu_scores_med_count)\n",
        "\n",
        "print(\"Average 4-gram bleu score of long sentences: \",bleu_scores_long/bleu_scores_long_count)\n",
        "print(\"Number of long sentences: \", bleu_scores_long_count)\n",
        "\n",
        "print(\"Average sentence length: \",sum(sentence_len)/len(its))\n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-acd7b6f3a16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0msampled_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0msampled_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-9b89a134b060>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, features, states)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# inputs: (batch_size, embed_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# inputs: (batch_size, 1, embed_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msampled_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# sampled_ids: (batch_size, max_seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msampled_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAr2ooq4cbR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_data = {\"sentence lengths\" : sentence_len}\n",
        "sentence_df = pd.DataFrame(sentence_data)\n",
        "sentence_df.hist(bins = (max(sentence_len)-min(sentence_len)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUmSb2MHEZw3",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M7KY9G3NI8l",
        "colab_type": "code",
        "outputId": "db94c43c-1378-4d0a-cf97-a990ce1ab08b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##########################################\n",
        "# Train the models\n",
        "##########################################\n",
        "total_step = len(train_loader)\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, captions, lengths, _) in enumerate(train_loader):\n",
        "\n",
        "        # Set mini-batch dataset\n",
        "        images = images.to(device)\n",
        "        captions = captions.to(device)\n",
        "\n",
        "        # Packed as well as we'll compare to the decoder outputs\n",
        "        targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
        "\n",
        "        # Forward, backward and optimize\n",
        "        features = encoder(images)\n",
        "        outputs = decoder(features, captions, lengths)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        # Zero gradients for both networks\n",
        "        decoder.zero_grad()\n",
        "        encoder.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print log info\n",
        "        if i % log_step == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch, num_epochs, i, total_step, loss.item()))\n",
        "        # If you want to save the model checkpoints - recommended once you have everything working\n",
        "        # Make sure to save RNN and LSTM versions separately\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    #path_enc = f\"/content/gdrive/My Drive/Flickr8k/encoder-{epoch+1}RNN.ckpt\"\n",
        "    #path_dec = f\"/content/gdrive/My Drive/Flickr8k/decoder-{epoch+1}RNN.ckpt\" \n",
        "    #torch.save(decoder.state_dict(), path_dec)\n",
        "    #torch.save(encoder.state_dict(), path_enc)\n",
        "\n",
        "print(losses)\n",
        "plt.plot(losses, label='Training Loss')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/5], Step [0/301], Loss: 8.1430\n",
            "Epoch [0/5], Step [10/301], Loss: 5.4341\n",
            "Epoch [0/5], Step [20/301], Loss: 4.9831\n",
            "Epoch [0/5], Step [30/301], Loss: 4.7954\n",
            "Epoch [0/5], Step [40/301], Loss: 4.3752\n",
            "Epoch [0/5], Step [50/301], Loss: 4.1348\n",
            "Epoch [0/5], Step [60/301], Loss: 3.9410\n",
            "Epoch [0/5], Step [70/301], Loss: 3.7505\n",
            "Epoch [0/5], Step [80/301], Loss: 3.6374\n",
            "Epoch [0/5], Step [90/301], Loss: 3.3112\n",
            "Epoch [0/5], Step [100/301], Loss: 3.5790\n",
            "Epoch [0/5], Step [110/301], Loss: 3.4239\n",
            "Epoch [0/5], Step [120/301], Loss: 3.5322\n",
            "Epoch [0/5], Step [130/301], Loss: 3.4298\n",
            "Epoch [0/5], Step [140/301], Loss: 3.4785\n",
            "Epoch [0/5], Step [150/301], Loss: 3.3937\n",
            "Epoch [0/5], Step [160/301], Loss: 3.3537\n",
            "Epoch [0/5], Step [170/301], Loss: 3.3392\n",
            "Epoch [0/5], Step [180/301], Loss: 3.1910\n",
            "Epoch [0/5], Step [190/301], Loss: 3.3271\n",
            "Epoch [0/5], Step [200/301], Loss: 3.4043\n",
            "Epoch [0/5], Step [210/301], Loss: 3.2767\n",
            "Epoch [0/5], Step [220/301], Loss: 3.1943\n",
            "Epoch [0/5], Step [230/301], Loss: 3.0612\n",
            "Epoch [0/5], Step [240/301], Loss: 3.1565\n",
            "Epoch [0/5], Step [250/301], Loss: 3.2345\n",
            "Epoch [0/5], Step [260/301], Loss: 2.9187\n",
            "Epoch [0/5], Step [270/301], Loss: 3.2055\n",
            "Epoch [0/5], Step [280/301], Loss: 3.0336\n",
            "Epoch [0/5], Step [290/301], Loss: 2.9324\n",
            "Epoch [0/5], Step [300/301], Loss: 2.9715\n",
            "Epoch [1/5], Step [0/301], Loss: 3.0531\n",
            "Epoch [1/5], Step [10/301], Loss: 2.8770\n",
            "Epoch [1/5], Step [20/301], Loss: 3.0431\n",
            "Epoch [1/5], Step [30/301], Loss: 3.0071\n",
            "Epoch [1/5], Step [40/301], Loss: 2.9647\n",
            "Epoch [1/5], Step [50/301], Loss: 3.0647\n",
            "Epoch [1/5], Step [60/301], Loss: 2.8720\n",
            "Epoch [1/5], Step [70/301], Loss: 2.9358\n",
            "Epoch [1/5], Step [80/301], Loss: 3.1101\n",
            "Epoch [1/5], Step [90/301], Loss: 2.9579\n",
            "Epoch [1/5], Step [100/301], Loss: 2.8938\n",
            "Epoch [1/5], Step [110/301], Loss: 2.8965\n",
            "Epoch [1/5], Step [120/301], Loss: 2.8882\n",
            "Epoch [1/5], Step [130/301], Loss: 2.8991\n",
            "Epoch [1/5], Step [140/301], Loss: 2.8152\n",
            "Epoch [1/5], Step [150/301], Loss: 2.8664\n",
            "Epoch [1/5], Step [160/301], Loss: 2.6917\n",
            "Epoch [1/5], Step [170/301], Loss: 2.8287\n",
            "Epoch [1/5], Step [180/301], Loss: 2.8007\n",
            "Epoch [1/5], Step [190/301], Loss: 2.8350\n",
            "Epoch [1/5], Step [200/301], Loss: 3.0236\n",
            "Epoch [1/5], Step [210/301], Loss: 2.8203\n",
            "Epoch [1/5], Step [220/301], Loss: 2.8594\n",
            "Epoch [1/5], Step [230/301], Loss: 2.7758\n",
            "Epoch [1/5], Step [240/301], Loss: 2.7915\n",
            "Epoch [1/5], Step [250/301], Loss: 2.7320\n",
            "Epoch [1/5], Step [260/301], Loss: 2.8162\n",
            "Epoch [1/5], Step [270/301], Loss: 2.8411\n",
            "Epoch [1/5], Step [280/301], Loss: 2.7230\n",
            "Epoch [1/5], Step [290/301], Loss: 2.8137\n",
            "Epoch [1/5], Step [300/301], Loss: 3.1017\n",
            "Epoch [2/5], Step [0/301], Loss: 2.6428\n",
            "Epoch [2/5], Step [10/301], Loss: 2.6764\n",
            "Epoch [2/5], Step [20/301], Loss: 2.6013\n",
            "Epoch [2/5], Step [30/301], Loss: 2.5104\n",
            "Epoch [2/5], Step [40/301], Loss: 2.6460\n",
            "Epoch [2/5], Step [50/301], Loss: 2.5869\n",
            "Epoch [2/5], Step [60/301], Loss: 2.6949\n",
            "Epoch [2/5], Step [70/301], Loss: 2.7435\n",
            "Epoch [2/5], Step [80/301], Loss: 2.6752\n",
            "Epoch [2/5], Step [90/301], Loss: 2.5420\n",
            "Epoch [2/5], Step [100/301], Loss: 2.6929\n",
            "Epoch [2/5], Step [110/301], Loss: 2.6008\n",
            "Epoch [2/5], Step [120/301], Loss: 2.6382\n",
            "Epoch [2/5], Step [130/301], Loss: 2.5929\n",
            "Epoch [2/5], Step [140/301], Loss: 2.6738\n",
            "Epoch [2/5], Step [150/301], Loss: 2.6596\n",
            "Epoch [2/5], Step [160/301], Loss: 2.5356\n",
            "Epoch [2/5], Step [170/301], Loss: 2.5931\n",
            "Epoch [2/5], Step [180/301], Loss: 2.5868\n",
            "Epoch [2/5], Step [190/301], Loss: 2.6388\n",
            "Epoch [2/5], Step [200/301], Loss: 2.7255\n",
            "Epoch [2/5], Step [210/301], Loss: 2.7439\n",
            "Epoch [2/5], Step [220/301], Loss: 2.5825\n",
            "Epoch [2/5], Step [230/301], Loss: 2.6456\n",
            "Epoch [2/5], Step [240/301], Loss: 2.6144\n",
            "Epoch [2/5], Step [250/301], Loss: 2.5758\n",
            "Epoch [2/5], Step [260/301], Loss: 2.5892\n",
            "Epoch [2/5], Step [270/301], Loss: 2.5253\n",
            "Epoch [2/5], Step [280/301], Loss: 2.5829\n",
            "Epoch [2/5], Step [290/301], Loss: 2.5656\n",
            "Epoch [2/5], Step [300/301], Loss: 2.5396\n",
            "Epoch [3/5], Step [0/301], Loss: 2.4675\n",
            "Epoch [3/5], Step [10/301], Loss: 2.4993\n",
            "Epoch [3/5], Step [20/301], Loss: 2.5038\n",
            "Epoch [3/5], Step [30/301], Loss: 2.5009\n",
            "Epoch [3/5], Step [40/301], Loss: 2.4189\n",
            "Epoch [3/5], Step [50/301], Loss: 2.4693\n",
            "Epoch [3/5], Step [60/301], Loss: 2.4767\n",
            "Epoch [3/5], Step [70/301], Loss: 2.2579\n",
            "Epoch [3/5], Step [80/301], Loss: 2.4723\n",
            "Epoch [3/5], Step [90/301], Loss: 2.3250\n",
            "Epoch [3/5], Step [100/301], Loss: 2.3410\n",
            "Epoch [3/5], Step [110/301], Loss: 2.4810\n",
            "Epoch [3/5], Step [120/301], Loss: 2.5078\n",
            "Epoch [3/5], Step [130/301], Loss: 2.4142\n",
            "Epoch [3/5], Step [140/301], Loss: 2.3746\n",
            "Epoch [3/5], Step [150/301], Loss: 2.5196\n",
            "Epoch [3/5], Step [160/301], Loss: 2.3984\n",
            "Epoch [3/5], Step [170/301], Loss: 2.5482\n",
            "Epoch [3/5], Step [180/301], Loss: 2.4497\n",
            "Epoch [3/5], Step [190/301], Loss: 2.2997\n",
            "Epoch [3/5], Step [200/301], Loss: 2.4319\n",
            "Epoch [3/5], Step [210/301], Loss: 2.4807\n",
            "Epoch [3/5], Step [220/301], Loss: 2.4491\n",
            "Epoch [3/5], Step [230/301], Loss: 2.4734\n",
            "Epoch [3/5], Step [240/301], Loss: 2.4815\n",
            "Epoch [3/5], Step [250/301], Loss: 2.5192\n",
            "Epoch [3/5], Step [260/301], Loss: 2.4583\n",
            "Epoch [3/5], Step [270/301], Loss: 2.4732\n",
            "Epoch [3/5], Step [280/301], Loss: 2.4875\n",
            "Epoch [3/5], Step [290/301], Loss: 2.4453\n",
            "Epoch [3/5], Step [300/301], Loss: 2.5118\n",
            "Epoch [4/5], Step [0/301], Loss: 2.2354\n",
            "Epoch [4/5], Step [10/301], Loss: 2.4063\n",
            "Epoch [4/5], Step [20/301], Loss: 2.3420\n",
            "Epoch [4/5], Step [30/301], Loss: 2.3168\n",
            "Epoch [4/5], Step [40/301], Loss: 2.2609\n",
            "Epoch [4/5], Step [50/301], Loss: 2.3092\n",
            "Epoch [4/5], Step [60/301], Loss: 2.2877\n",
            "Epoch [4/5], Step [70/301], Loss: 2.3651\n",
            "Epoch [4/5], Step [80/301], Loss: 2.3129\n",
            "Epoch [4/5], Step [90/301], Loss: 2.3628\n",
            "Epoch [4/5], Step [100/301], Loss: 2.3244\n",
            "Epoch [4/5], Step [110/301], Loss: 2.3601\n",
            "Epoch [4/5], Step [120/301], Loss: 2.4277\n",
            "Epoch [4/5], Step [130/301], Loss: 2.2834\n",
            "Epoch [4/5], Step [140/301], Loss: 2.3984\n",
            "Epoch [4/5], Step [150/301], Loss: 2.4079\n",
            "Epoch [4/5], Step [160/301], Loss: 2.4083\n",
            "Epoch [4/5], Step [170/301], Loss: 2.3171\n",
            "Epoch [4/5], Step [180/301], Loss: 2.3240\n",
            "Epoch [4/5], Step [190/301], Loss: 2.3112\n",
            "Epoch [4/5], Step [200/301], Loss: 2.3131\n",
            "Epoch [4/5], Step [210/301], Loss: 2.2637\n",
            "Epoch [4/5], Step [220/301], Loss: 2.3957\n",
            "Epoch [4/5], Step [230/301], Loss: 2.4465\n",
            "Epoch [4/5], Step [240/301], Loss: 2.3718\n",
            "Epoch [4/5], Step [250/301], Loss: 2.2483\n",
            "Epoch [4/5], Step [260/301], Loss: 2.2480\n",
            "Epoch [4/5], Step [270/301], Loss: 2.2542\n",
            "Epoch [4/5], Step [280/301], Loss: 2.3489\n",
            "Epoch [4/5], Step [290/301], Loss: 2.3720\n",
            "Epoch [4/5], Step [300/301], Loss: 2.6309\n",
            "[8.142962455749512, 7.906448841094971, 7.645326614379883, 7.321667194366455, 6.852051258087158, 6.293902397155762, 5.890485763549805, 5.611364364624023, 5.556624412536621, 5.436273097991943, 5.434102535247803, 5.219043731689453, 5.313249588012695, 5.331630706787109, 5.2268595695495605, 5.247203350067139, 5.192149639129639, 5.148615837097168, 5.109166145324707, 4.998488903045654, 4.9831414222717285, 5.093628406524658, 5.019515514373779, 4.970028400421143, 4.883707046508789, 4.810000896453857, 4.860418319702148, 4.855897426605225, 4.741363525390625, 4.775163650512695, 4.795380592346191, 4.696662425994873, 4.696073532104492, 4.723814964294434, 4.695101261138916, 4.620075225830078, 4.5189056396484375, 4.463840484619141, 4.459953784942627, 4.5055036544799805, 4.375225067138672, 4.383231163024902, 4.313072681427002, 4.130782127380371, 4.360440254211426, 4.233670234680176, 4.195022106170654, 4.1699018478393555, 4.126996040344238, 4.129894733428955, 4.134766101837158, 4.106445789337158, 4.01850700378418, 4.0650553703308105, 3.9202582836151123, 4.048904895782471, 4.046930313110352, 4.010210990905762, 4.004580974578857, 4.093085289001465, 3.940966844558716, 3.9052679538726807, 3.780362844467163, 3.832949638366699, 3.8376150131225586, 3.7645621299743652, 3.7817647457122803, 3.721371650695801, 3.786546230316162, 3.8531582355499268, 3.7505099773406982, 3.8422470092773438, 3.813647747039795, 3.6538963317871094, 3.6014838218688965, 3.849444627761841, 3.744961738586426, 3.6548736095428467, 3.7558889389038086, 3.7359273433685303, 3.637362241744995, 3.7763233184814453, 3.7047910690307617, 3.760040760040283, 3.636103630065918, 3.6064510345458984, 3.573228597640991, 3.719762086868286, 3.714517831802368, 3.585963010787964, 3.3112282752990723, 3.553924798965454, 3.708597183227539, 3.563690662384033, 3.643537998199463, 3.6808035373687744, 3.5016753673553467, 3.5711400508880615, 3.5868349075317383, 3.58825945854187, 3.578967809677124, 3.505664110183716, 3.6908633708953857, 3.543290853500366, 3.637563467025757, 3.541714668273926, 3.5435893535614014, 3.4754257202148438, 3.6022942066192627, 3.527169942855835, 3.423901319503784, 3.5874927043914795, 3.4991862773895264, 3.5010340213775635, 3.5647754669189453, 3.391417980194092, 3.4072015285491943, 3.475419282913208, 3.662069797515869, 3.488729238510132, 3.5321807861328125, 3.5282413959503174, 3.5176303386688232, 3.2797598838806152, 3.4642083644866943, 3.4075307846069336, 3.4253807067871094, 3.478726387023926, 3.506283760070801, 3.435147285461426, 3.4297735691070557, 3.401035785675049, 3.5696630477905273, 3.4132421016693115, 3.539673089981079, 3.3830761909484863, 3.3971643447875977, 3.47861385345459, 3.3939831256866455, 3.4698379039764404, 3.478501081466675, 3.336332321166992, 3.4238927364349365, 3.246654748916626, 3.4743294715881348, 3.4035680294036865, 3.382840156555176, 3.3241031169891357, 3.4323487281799316, 3.332659959793091, 3.393667697906494, 3.3848137855529785, 3.3146843910217285, 3.434783935546875, 3.366776943206787, 3.2929134368896484, 3.246344566345215, 3.326056480407715, 3.372626781463623, 3.3282718658447266, 3.3537471294403076, 3.413386344909668, 3.380443811416626, 3.382505178451538, 3.2542660236358643, 3.255713939666748, 3.456071615219116, 3.383401870727539, 3.3451244831085205, 3.2586729526519775, 3.33921217918396, 3.2275917530059814, 3.403010129928589, 3.26924467086792, 3.3805036544799805, 3.200115442276001, 3.3033254146575928, 3.306593894958496, 3.2196552753448486, 3.3846442699432373, 3.190995216369629, 3.1969032287597656, 3.301663875579834, 3.335580587387085, 3.3695991039276123, 3.2804555892944336, 3.333359956741333, 3.2730913162231445, 3.2549896240234375, 3.3308770656585693, 3.3271310329437256, 3.218804359436035, 3.249467372894287, 3.267698287963867, 3.2566895484924316, 3.3261139392852783, 3.4563674926757812, 3.136589288711548, 3.2203128337860107, 3.228750467300415, 3.4043333530426025, 3.180814504623413, 3.263537645339966, 3.1622211933135986, 3.267241954803467, 3.2977678775787354, 3.362668752670288, 3.2034366130828857, 3.270676612854004, 3.1600756645202637, 3.2766761779785156, 3.0873401165008545, 3.287961721420288, 3.028930187225342, 3.141223192214966, 3.152859687805176, 3.032930374145508, 3.1940557956695557, 3.0932891368865967, 3.1603379249572754, 3.1942949295043945, 3.162921905517578, 3.2015037536621094, 3.220787286758423, 3.2178292274475098, 3.1184778213500977, 3.159907817840576, 3.1066458225250244, 3.302175283432007, 2.91172194480896, 3.0612270832061768, 3.3178420066833496, 3.1396639347076416, 3.102058172225952, 3.2234621047973633, 3.2355358600616455, 3.251659631729126, 3.0618276596069336, 3.1924080848693848, 3.1264307498931885, 3.15647292137146, 3.0023508071899414, 3.253679037094116, 3.2400286197662354, 3.250537633895874, 3.1514148712158203, 3.078796148300171, 3.212242603302002, 3.1490159034729004, 2.990196466445923, 3.2344958782196045, 3.127286434173584, 3.1512093544006348, 3.1408493518829346, 3.2106873989105225, 3.0468032360076904, 3.172985076904297, 3.206681489944458, 3.048574686050415, 3.258650779724121, 2.918745756149292, 3.1578280925750732, 3.1578943729400635, 3.123795509338379, 3.070798397064209, 3.1797726154327393, 3.1769490242004395, 3.188845157623291, 3.114454746246338, 3.1331303119659424, 3.2054598331451416, 2.9842629432678223, 3.113769769668579, 2.9942450523376465, 3.109463930130005, 3.0391299724578857, 3.080496072769165, 3.0693650245666504, 3.1049814224243164, 3.0076637268066406, 3.0335819721221924, 3.0026674270629883, 3.067016124725342, 3.188727378845215, 3.1625964641571045, 3.186551332473755, 3.1278951168060303, 2.973116397857666, 2.992495059967041, 3.026442766189575, 2.9324402809143066, 3.052239179611206, 3.1639630794525146, 3.011813163757324, 3.1625633239746094, 3.136493682861328, 3.099231243133545, 2.9205782413482666, 3.119481325149536, 3.1440610885620117, 2.9715240001678467, 3.0530858039855957, 3.1888222694396973, 2.896411180496216, 2.966261386871338, 2.9694249629974365, 3.0228538513183594, 2.9337286949157715, 3.056670665740967, 2.9153616428375244, 3.0277512073516846, 2.8770477771759033, 2.9488749504089355, 2.9552502632141113, 2.944315195083618, 3.1048083305358887, 2.866377592086792, 2.8075971603393555, 2.806774616241455, 2.9484403133392334, 2.8545584678649902, 3.0431199073791504, 3.0134170055389404, 2.9385194778442383, 2.9043922424316406, 2.8692336082458496, 2.987853527069092, 3.0326309204101562, 2.983592987060547, 3.076401472091675, 2.9767682552337646, 3.0070769786834717, 2.879570245742798, 2.9459989070892334, 2.9607481956481934, 2.9453372955322266, 2.821889638900757, 2.9589107036590576, 3.0094077587127686, 2.987992286682129, 2.9045469760894775, 2.9646871089935303, 2.876887083053589, 2.975219964981079, 2.9670543670654297, 3.0825271606445312, 2.920624256134033, 3.0742831230163574, 2.9232301712036133, 2.9416840076446533, 3.033965826034546, 3.0646634101867676, 2.8810839653015137, 2.8985939025878906, 2.8401737213134766, 2.9886276721954346, 3.012862205505371, 2.927311658859253, 2.942634344100952, 2.9765384197235107, 3.0068652629852295, 2.8720009326934814, 2.99824857711792, 2.8463315963745117, 3.117108106613159, 2.8431811332702637, 2.8881945610046387, 2.8687117099761963, 2.9146010875701904, 2.9174399375915527, 2.887030839920044, 2.9358317852020264, 2.945948362350464, 2.778866767883301, 2.9163994789123535, 2.8774068355560303, 2.907639265060425, 2.8669819831848145, 2.9947712421417236, 2.9030256271362305, 2.9697506427764893, 3.1101322174072266, 2.948209762573242, 3.036391258239746, 2.925774574279785, 2.899430990219116, 2.8176486492156982, 2.9732820987701416, 2.9507639408111572, 2.8653147220611572, 3.0058066844940186, 2.9578757286071777, 2.8306024074554443, 2.925476551055908, 3.0001068115234375, 2.900360345840454, 2.8010199069976807, 2.853059768676758, 2.8417253494262695, 2.9003684520721436, 2.855592966079712, 2.893840789794922, 2.956554412841797, 2.852006196975708, 2.8293375968933105, 3.051793336868286, 3.0234766006469727, 2.9842939376831055, 2.862607955932617, 2.972792863845825, 3.0051496028900146, 2.8965320587158203, 2.734278917312622, 2.8477470874786377, 3.0406198501586914, 2.6867024898529053, 2.9202563762664795, 2.878077983856201, 2.9540810585021973, 2.8587300777435303, 2.9076004028320312, 2.888240337371826, 2.816929340362549, 2.8628158569335938, 2.82850980758667, 2.9074342250823975, 2.876979351043701, 2.8314523696899414, 2.89267897605896, 2.9605331420898438, 2.8299596309661865, 2.8991172313690186, 2.904123067855835, 2.8582475185394287, 2.8807897567749023, 2.790757179260254, 2.9267399311065674, 2.861999273300171, 2.808061122894287, 2.786423444747925, 2.8296072483062744, 2.815199851989746, 2.9361038208007812, 2.8194189071655273, 2.768946647644043, 2.8520970344543457, 2.7794413566589355, 2.7918999195098877, 2.8776051998138428, 2.743483066558838, 2.871983528137207, 2.866368532180786, 2.825655698776245, 2.9189085960388184, 2.9541051387786865, 2.8211615085601807, 2.8640410900115967, 2.809215545654297, 2.7836475372314453, 2.678229331970215, 2.758451223373413, 2.691744327545166, 2.837311267852783, 2.9171857833862305, 2.879455089569092, 2.947314500808716, 2.9715099334716797, 2.721691846847534, 2.8616445064544678, 3.0172955989837646, 2.8465826511383057, 2.8286819458007812, 2.839437961578369, 2.8872952461242676, 2.827578544616699, 2.7040486335754395, 2.921928644180298, 2.7614009380340576, 2.7506704330444336, 2.763871431350708, 2.835740804672241, 2.800687074661255, 2.8317654132843018, 2.840564489364624, 2.9028096199035645, 2.797067403793335, 2.9484760761260986, 2.9321703910827637, 2.8941829204559326, 2.825317144393921, 2.843297004699707, 2.835002899169922, 2.803114891052246, 2.9223744869232178, 2.755276679992676, 2.8049890995025635, 2.7738683223724365, 2.883878231048584, 2.7579634189605713, 2.8205134868621826, 2.7537660598754883, 3.0236055850982666, 2.8265280723571777, 2.816908359527588, 2.998530387878418, 2.813284158706665, 2.822737455368042, 2.8614022731781006, 2.730057954788208, 2.7868573665618896, 2.6764683723449707, 2.820261240005493, 2.970498561859131, 2.7482948303222656, 2.916689157485962, 2.8089969158172607, 2.9389119148254395, 2.831866979598999, 2.811194896697998, 2.7843658924102783, 2.7942636013031006, 2.8593828678131104, 2.878720760345459, 2.777522563934326, 2.7698252201080322, 2.848219156265259, 2.771366596221924, 2.721731424331665, 2.796788454055786, 2.6848652362823486, 2.7731640338897705, 2.775824546813965, 2.8608181476593018, 2.783413887023926, 2.910682201385498, 2.8646152019500732, 2.7631592750549316, 2.7718405723571777, 2.9464805126190186, 2.7838056087493896, 2.7828783988952637, 2.791508197784424, 2.959461212158203, 2.7386486530303955, 2.8891546726226807, 2.7673702239990234, 2.782254457473755, 2.8175835609436035, 2.8350040912628174, 2.8628194332122803, 2.672212600708008, 2.731957197189331, 2.728487014770508, 2.6894752979278564, 2.8088877201080322, 2.5975561141967773, 2.850025177001953, 2.70141339302063, 2.856091022491455, 2.8177151679992676, 2.7077465057373047, 2.816232204437256, 2.6699440479278564, 2.6702215671539307, 2.8647594451904297, 2.9182674884796143, 2.8288233280181885, 2.6748690605163574, 2.7218003273010254, 2.8563199043273926, 2.9130520820617676, 2.841111898422241, 2.7442712783813477, 2.7322795391082764, 2.8666343688964844, 2.763692855834961, 2.8284695148468018, 2.715609550476074, 2.662130355834961, 2.859525680541992, 2.868443012237549, 2.7229714393615723, 2.789848804473877, 2.6871278285980225, 2.82675838470459, 2.861910820007324, 2.9210152626037598, 2.913999319076538, 2.7269210815429688, 2.7866525650024414, 2.6334545612335205, 2.8136582374572754, 2.703469753265381, 2.796194314956665, 2.8853647708892822, 2.916599750518799, 2.9155287742614746, 2.7906415462493896, 2.891561985015869, 2.773219347000122, 2.8408238887786865, 3.1017165184020996, 2.6427853107452393, 2.619004249572754, 2.6663031578063965, 2.643786907196045, 2.6165096759796143, 2.7928175926208496, 2.5231821537017822, 2.564340353012085, 2.617072343826294, 2.6693267822265625, 2.6763575077056885, 2.705864667892456, 2.5941762924194336, 2.690161943435669, 2.484736919403076, 2.6362123489379883, 2.616446018218994, 2.6870079040527344, 2.6517038345336914, 2.677307367324829, 2.6012966632843018, 2.730408191680908, 2.6611812114715576, 2.662764310836792, 2.658912420272827, 2.6732687950134277, 2.494609832763672, 2.6327524185180664, 2.667832374572754, 2.6069746017456055, 2.5103814601898193, 2.6243772506713867, 2.6483957767486572, 2.6531078815460205, 2.6994731426239014, 2.7413177490234375, 2.673405408859253, 2.6330888271331787, 2.633574962615967, 2.6800997257232666, 2.645969867706299, 2.633958339691162, 2.6986334323883057, 2.59672474861145, 2.596886396408081, 2.5584824085235596, 2.6978533267974854, 2.680199384689331, 2.6545355319976807, 2.497544527053833, 2.58687162399292, 2.5585155487060547, 2.6110708713531494, 2.7135066986083984, 2.6178805828094482, 2.6406607627868652, 2.672454595565796, 2.6568329334259033, 2.5364561080932617, 2.595303773880005, 2.694939136505127, 2.666560649871826, 2.6486353874206543, 2.6291606426239014, 2.6069788932800293, 2.7212181091308594, 2.4652950763702393, 2.7202632427215576, 2.6118743419647217, 2.778188943862915, 2.7434706687927246, 2.8581337928771973, 2.8225386142730713, 2.664963960647583, 2.689974546432495, 2.6503093242645264, 2.681603193283081, 2.6090798377990723, 2.684670925140381, 2.6202285289764404, 2.6751887798309326, 2.6314821243286133, 2.7916646003723145, 2.672088146209717, 2.631434679031372, 2.6559338569641113, 2.559915542602539, 2.645406723022461, 2.626347541809082, 2.6606602668762207, 2.542001485824585, 2.7034997940063477, 2.7078914642333984, 2.5720388889312744, 2.531047821044922, 2.6440823078155518, 2.6757051944732666, 2.618194341659546, 2.7759218215942383, 2.644066572189331, 2.692918062210083, 2.6058294773101807, 2.5128672122955322, 2.620551109313965, 2.716214179992676, 2.688560724258423, 2.6685941219329834, 2.7398598194122314, 2.539654493331909, 2.6527113914489746, 2.600827693939209, 2.6734089851379395, 2.647371530532837, 2.6219918727874756, 2.548246383666992, 2.5886855125427246, 2.6569759845733643, 2.594386577606201, 2.572220802307129, 2.6632864475250244, 2.63822078704834, 2.7826576232910156, 2.669419288635254, 2.6697397232055664, 2.540872812271118, 2.680783748626709, 2.5840182304382324, 2.5921168327331543, 2.561917781829834, 2.667064666748047, 2.5928704738616943, 2.6204097270965576, 2.5955276489257812, 2.728539228439331, 2.6299846172332764, 2.573861837387085, 2.6406219005584717, 2.5601818561553955, 2.6290605068206787, 2.579911708831787, 2.673778772354126, 2.679682731628418, 2.730494499206543, 2.7198123931884766, 2.605499744415283, 2.719486951828003, 2.621537923812866, 2.5848281383514404, 2.5244789123535156, 2.660263776779175, 2.6596293449401855, 2.799461603164673, 2.5938117504119873, 2.638711929321289, 2.545793294906616, 2.5978806018829346, 2.674345016479492, 2.670651435852051, 2.62819504737854, 2.7456724643707275, 2.535576820373535, 2.548668622970581, 2.5573904514312744, 2.5865445137023926, 2.681520462036133, 2.5500292778015137, 2.530071496963501, 2.640718698501587, 2.5591490268707275, 2.662320852279663, 2.5931155681610107, 2.682041883468628, 2.669650077819824, 2.6757614612579346, 2.7273643016815186, 2.6686363220214844, 2.551295280456543, 2.6546497344970703, 2.599801540374756, 2.557992935180664, 2.586750030517578, 2.593843936920166, 2.641221523284912, 2.6760904788970947, 2.482588768005371, 2.5903642177581787, 2.7328455448150635, 2.4742417335510254, 2.6840262413024902, 2.673161745071411, 2.638810157775879, 2.597153663635254, 2.5431718826293945, 2.670437812805176, 2.588165760040283, 2.6480441093444824, 2.6745412349700928, 2.5522139072418213, 2.646824836730957, 2.54368257522583, 2.7255403995513916, 2.5197908878326416, 2.544269561767578, 2.6479625701904297, 2.708836793899536, 2.614598035812378, 2.494590997695923, 2.619704008102417, 2.6068575382232666, 2.5412957668304443, 2.7438955307006836, 2.5336554050445557, 2.5304067134857178, 2.5696444511413574, 2.508544683456421, 2.581295967102051, 2.750269889831543, 2.4825093746185303, 2.4589672088623047, 2.5242197513580322, 2.582454204559326, 2.677872657775879, 2.6620078086853027, 2.562283992767334, 2.6655068397521973, 2.66382098197937, 2.7253270149230957, 2.4932634830474854, 2.6688454151153564, 2.6548380851745605, 2.645576238632202, 2.6171748638153076, 2.591798782348633, 2.622457981109619, 2.672194004058838, 2.6474480628967285, 2.7116057872772217, 2.591013193130493, 2.542487859725952, 2.529648780822754, 2.6143972873687744, 2.6233561038970947, 2.620013952255249, 2.662757396697998, 2.613358974456787, 2.505077362060547, 2.6237387657165527, 2.7087409496307373, 2.6021714210510254, 2.6638247966766357, 2.575814962387085, 2.522407293319702, 2.4888837337493896, 2.6169402599334717, 2.5866353511810303, 2.5567004680633545, 2.527282476425171, 2.517678737640381, 2.5145695209503174, 2.6014745235443115, 2.5892186164855957, 2.611510753631592, 2.6055855751037598, 2.6942975521087646, 2.629255533218384, 2.4611752033233643, 2.5878920555114746, 2.5955567359924316, 2.6461238861083984, 2.6797409057617188, 2.525322914123535, 2.4616973400115967, 2.596590042114258, 2.605652332305908, 2.510920524597168, 2.635132312774658, 2.4764206409454346, 2.5532033443450928, 2.6318857669830322, 2.6447486877441406, 2.5829358100891113, 2.6639668941497803, 2.681333065032959, 2.653055429458618, 2.6775765419006348, 2.607823610305786, 2.6004831790924072, 2.623626947402954, 2.527751922607422, 2.5609211921691895, 2.5655999183654785, 2.6588141918182373, 2.7533373832702637, 2.4992613792419434, 2.644782066345215, 2.591294050216675, 2.624403476715088, 2.5541813373565674, 2.557318687438965, 2.63006854057312, 2.5396177768707275, 2.4674899578094482, 2.3738725185394287, 2.4727942943573, 2.3799498081207275, 2.6098339557647705, 2.4840643405914307, 2.4580235481262207, 2.4956858158111572, 2.4042584896087646, 2.591439723968506, 2.499264717102051, 2.4083704948425293, 2.3368871212005615, 2.4186007976531982, 2.495194435119629, 2.479492664337158, 2.496544122695923, 2.4782094955444336, 2.425074338912964, 2.4598278999328613, 2.503751754760742, 2.4777932167053223, 2.3959543704986572, 2.409719228744507, 2.4160025119781494, 2.4438977241516113, 2.442052125930786, 2.4863932132720947, 2.5537731647491455, 2.5231096744537354, 2.5008645057678223, 2.3683688640594482, 2.463925361633301, 2.4203202724456787, 2.5208678245544434, 2.4825541973114014, 2.4028732776641846, 2.4567182064056396, 2.6092655658721924, 2.4419758319854736, 2.418923854827881, 2.4588873386383057, 2.359835147857666, 2.5053999423980713, 2.3958449363708496, 2.4528439044952393, 2.472623586654663, 2.279524087905884, 2.484389305114746, 2.4420583248138428, 2.469264030456543, 2.3712737560272217, 2.4570977687835693, 2.6023733615875244, 2.3938989639282227, 2.2635457515716553, 2.5780446529388428, 2.4353291988372803, 2.549635887145996, 2.494560718536377, 2.4766714572906494, 2.502441644668579, 2.3748748302459717, 2.5655429363250732, 2.3585004806518555, 2.3490707874298096, 2.412677764892578, 2.381197214126587, 2.474876642227173, 2.431269884109497, 2.257861852645874, 2.4706192016601562, 2.4577436447143555, 2.4851579666137695, 2.491758108139038, 2.4255897998809814, 2.4693005084991455, 2.436337471008301, 2.5540199279785156, 2.270193099975586, 2.472327709197998, 2.510606050491333, 2.4846739768981934, 2.4160220623016357, 2.4458367824554443, 2.4442713260650635, 2.490175724029541, 2.400327205657959, 2.4762723445892334, 2.3872270584106445, 2.324962615966797, 2.5333445072174072, 2.596473455429077, 2.541451930999756, 2.494591474533081, 2.3868863582611084, 2.5118134021759033, 2.5165176391601562, 2.397299289703369, 2.482313632965088, 2.341040849685669, 2.546720027923584, 2.4237935543060303, 2.3333518505096436, 2.4863996505737305, 2.4517226219177246, 2.3677780628204346, 2.3823258876800537, 2.36195707321167, 2.6000688076019287, 2.4809861183166504, 2.4445648193359375, 2.533431053161621, 2.3540093898773193, 2.462414264678955, 2.4835026264190674, 2.4401235580444336, 2.3985743522644043, 2.536062479019165, 2.5579288005828857, 2.5077877044677734, 2.518345832824707, 2.4857566356658936, 2.5180420875549316, 2.534304141998291, 2.4261274337768555, 2.429631471633911, 2.4792542457580566, 2.5364158153533936, 2.451728343963623, 2.4142208099365234, 2.494037389755249, 2.3970394134521484, 2.444798231124878, 2.533818244934082, 2.3132858276367188, 2.568129777908325, 2.4363389015197754, 2.487574338912964, 2.483631134033203, 2.3745858669281006, 2.4570701122283936, 2.3899996280670166, 2.513354778289795, 2.437636137008667, 2.5317490100860596, 2.47689151763916, 2.3418264389038086, 2.4773197174072266, 2.4820926189422607, 2.5196034908294678, 2.4453859329223633, 2.4125471115112305, 2.4881889820098877, 2.444796562194824, 2.5002222061157227, 2.382254123687744, 2.4443373680114746, 2.4123029708862305, 2.4177746772766113, 2.3983962535858154, 2.5006895065307617, 2.414480447769165, 2.406916618347168, 2.5446786880493164, 2.616173267364502, 2.3815701007843018, 2.5043342113494873, 2.5107290744781494, 2.502875804901123, 2.5482113361358643, 2.4156670570373535, 2.4822380542755127, 2.3744771480560303, 2.3420474529266357, 2.4052932262420654, 2.513140916824341, 2.4408786296844482, 2.438152551651001, 2.4294166564941406, 2.4497313499450684, 2.5178134441375732, 2.5186362266540527, 2.438778877258301, 2.529245376586914, 2.3823800086975098, 2.412635564804077, 2.4466538429260254, 2.462493658065796, 2.53523325920105, 2.2997422218322754, 2.473766565322876, 2.448812484741211, 2.4578659534454346, 2.4551198482513428, 2.5434465408325195, 2.530592918395996, 2.397123098373413, 2.416175603866577, 2.484800338745117, 2.4319050312042236, 2.4960336685180664, 2.4831089973449707, 2.3932900428771973, 2.410031318664551, 2.457540988922119, 2.427469253540039, 2.290916681289673, 2.4496521949768066, 2.363553524017334, 2.480701446533203, 2.5008039474487305, 2.379728317260742, 2.412372350692749, 2.5821893215179443, 2.5204904079437256, 2.5515644550323486, 2.4451706409454346, 2.5452358722686768, 2.4530436992645264, 2.449084997177124, 2.4965620040893555, 2.554436445236206, 2.5521209239959717, 2.4730384349823, 2.524294137954712, 2.4256021976470947, 2.526245594024658, 2.5604820251464844, 2.5370097160339355, 2.4734206199645996, 2.3704206943511963, 2.4720845222473145, 2.5186707973480225, 2.3915817737579346, 2.406975269317627, 2.4962146282196045, 2.3701910972595215, 2.4417388439178467, 2.5580344200134277, 2.4814975261688232, 2.5912907123565674, 2.533450126647949, 2.4780447483062744, 2.561174154281616, 2.431910753250122, 2.4579269886016846, 2.4693784713745117, 2.3966829776763916, 2.606987476348877, 2.519192934036255, 2.5840775966644287, 2.5294735431671143, 2.542095899581909, 2.603555917739868, 2.4894375801086426, 2.5560646057128906, 2.521327018737793, 2.3437321186065674, 2.541992425918579, 2.4582550525665283, 2.3971354961395264, 2.4913675785064697, 2.5543439388275146, 2.386617422103882, 2.4831297397613525, 2.429469585418701, 2.4175167083740234, 2.350712537765503, 2.4736897945404053, 2.4732327461242676, 2.567253351211548, 2.387545347213745, 2.53975772857666, 2.4801535606384277, 2.5344460010528564, 2.369642734527588, 2.521857500076294, 2.451693058013916, 2.3707940578460693, 2.487548589706421, 2.4485325813293457, 2.437228202819824, 2.502236843109131, 2.5410361289978027, 2.475337505340576, 2.458009719848633, 2.4568896293640137, 2.380282163619995, 2.4051668643951416, 2.445319175720215, 2.4289886951446533, 2.5173680782318115, 2.48007869720459, 2.4206297397613525, 2.5014545917510986, 2.431330680847168, 2.5049102306365967, 2.4421496391296387, 2.3807053565979004, 2.5118048191070557, 2.235354423522949, 2.2674953937530518, 2.374992847442627, 2.4115829467773438, 2.3160645961761475, 2.3392441272735596, 2.2362701892852783, 2.3177855014801025, 2.2861216068267822, 2.301537036895752, 2.4063026905059814, 2.3662402629852295, 2.391496419906616, 2.3207597732543945, 2.306908130645752, 2.3527913093566895, 2.3565218448638916, 2.2923290729522705, 2.460291624069214, 2.5409140586853027, 2.3420114517211914, 2.383577346801758, 2.3487744331359863, 2.414645195007324, 2.311267852783203, 2.296081066131592, 2.288569927215576, 2.265861988067627, 2.303690195083618, 2.240753650665283, 2.316826343536377, 2.4185540676116943, 2.2772035598754883, 2.3095450401306152, 2.364853858947754, 2.290390968322754, 2.3001902103424072, 2.227834701538086, 2.332967758178711, 2.2817959785461426, 2.2609002590179443, 2.304464101791382, 2.40102481842041, 2.2983450889587402, 2.2238211631774902, 2.3351426124572754, 2.3197922706604004, 2.3027238845825195, 2.4017727375030518, 2.3409078121185303, 2.309218168258667, 2.3198416233062744, 2.313117027282715, 2.4976701736450195, 2.377943754196167, 2.3778109550476074, 2.269746780395508, 2.244375705718994, 2.324442148208618, 2.4637651443481445, 2.2877213954925537, 2.3319497108459473, 2.3325726985931396, 2.3116838932037354, 2.3322060108184814, 2.328155517578125, 2.193072557449341, 2.2062668800354004, 2.3233542442321777, 2.488008499145508, 2.3651373386383057, 2.308070421218872, 2.3125522136688232, 2.3246164321899414, 2.414740800857544, 2.324687957763672, 2.299211263656616, 2.20711088180542, 2.3573341369628906, 2.3013389110565186, 2.3128514289855957, 2.2889835834503174, 2.3889827728271484, 2.3976917266845703, 2.3632640838623047, 2.44309663772583, 2.3537349700927734, 2.3880531787872314, 2.2261157035827637, 2.190598249435425, 2.3627736568450928, 2.327650547027588, 2.286215305328369, 2.254438638687134, 2.3267486095428467, 2.251798629760742, 2.365514039993286, 2.3804681301116943, 2.2908432483673096, 2.3326480388641357, 2.3243634700775146, 2.372814893722534, 2.3686578273773193, 2.3335859775543213, 2.3315298557281494, 2.326314687728882, 2.2787985801696777, 2.407766819000244, 2.3236935138702393, 2.376943349838257, 2.360100507736206, 2.299391269683838, 2.3507397174835205, 2.291564464569092, 2.3830504417419434, 2.379927396774292, 2.3641419410705566, 2.3183724880218506, 2.235365152359009, 2.2582924365997314, 2.427720308303833, 2.4682650566101074, 2.3212668895721436, 2.3414835929870605, 2.195061683654785, 2.363461494445801, 2.2682688236236572, 2.3469674587249756, 2.4704792499542236, 2.3030309677124023, 2.283431053161621, 2.4430103302001953, 2.3268775939941406, 2.3004181385040283, 2.3575034141540527, 2.3723928928375244, 2.329393148422241, 2.4213156700134277, 2.3124239444732666, 2.367319107055664, 2.3984148502349854, 2.3529577255249023, 2.425117015838623, 2.377009391784668, 2.4289774894714355, 2.3353567123413086, 2.310279607772827, 2.2902591228485107, 2.313871383666992, 2.3891079425811768, 2.4078779220581055, 2.289377450942993, 2.3944897651672363, 2.3827884197235107, 2.302232265472412, 2.3744750022888184, 2.3123786449432373, 2.4685919284820557, 2.310436964035034, 2.3413825035095215, 2.4082584381103516, 2.398125648498535, 2.3820719718933105, 2.2433550357818604, 2.3094873428344727, 2.475193738937378, 2.3410654067993164, 2.344740152359009, 2.3159217834472656, 2.4292330741882324, 2.317124605178833, 2.2423243522644043, 2.3055641651153564, 2.3895111083984375, 2.3535380363464355, 2.3449432849884033, 2.38519549369812, 2.345890522003174, 2.227229356765747, 2.4623429775238037, 2.323974609375, 2.2608604431152344, 2.5163869857788086, 2.4039368629455566, 2.224013566970825, 2.4531099796295166, 2.245673418045044, 2.2636609077453613, 2.4049627780914307, 2.3675050735473633, 2.311244010925293, 2.4777634143829346, 2.2513718605041504, 2.3156638145446777, 2.309161424636841, 2.3735263347625732, 2.396397829055786, 2.2333507537841797, 2.275125741958618, 2.4283368587493896, 2.313141345977783, 2.25020432472229, 2.208767890930176, 2.2319021224975586, 2.257727861404419, 2.303870916366577, 2.383162021636963, 2.395507335662842, 2.2497901916503906, 2.299790382385254, 2.2636876106262207, 2.2775700092315674, 2.2786266803741455, 2.3669986724853516, 2.266357660293579, 2.278071403503418, 2.323045253753662, 2.3136940002441406, 2.3633034229278564, 2.262418270111084, 2.3957300186157227, 2.2745070457458496, 2.305851936340332, 2.3216683864593506, 2.3556883335113525, 2.2807159423828125, 2.348834276199341, 2.2881593704223633, 2.2398264408111572, 2.5302746295928955, 2.4464807510375977, 2.344353199005127, 2.3681232929229736, 2.3368277549743652, 2.3774771690368652, 2.3845510482788086, 2.227278232574463, 2.353245496749878, 2.4007983207702637, 2.294595718383789, 2.371779441833496, 2.3505656719207764, 2.219834089279175, 2.4106616973876953, 2.2502024173736572, 2.367940664291382, 2.291832685470581, 2.3330705165863037, 2.2988812923431396, 2.402167320251465, 2.2483444213867188, 2.3419575691223145, 2.397778272628784, 2.363363265991211, 2.3790321350097656, 2.3632278442382812, 2.359619617462158, 2.2878873348236084, 2.3851802349090576, 2.3362128734588623, 2.2480361461639404, 2.5388355255126953, 2.368846893310547, 2.379035472869873, 2.3819432258605957, 2.287295341491699, 2.4367311000823975, 2.3535163402557373, 2.2985196113586426, 2.3102288246154785, 2.254178762435913, 2.23646879196167, 2.32027268409729, 2.2746188640594482, 2.2686409950256348, 2.415168523788452, 2.290440797805786, 2.4096274375915527, 2.3240835666656494, 2.308670997619629, 2.348879337310791, 2.3928184509277344, 2.38411021232605, 2.3973186016082764, 2.3571150302886963, 2.361860513687134, 2.438941717147827, 2.353611469268799, 2.2998998165130615, 2.3013436794281006, 2.3719840049743652, 2.3229339122772217, 2.3657755851745605, 2.3568027019500732, 2.350372791290283, 2.4434125423431396, 2.33064603805542, 2.370842695236206, 2.350764513015747, 2.2414753437042236, 2.6308536529541016]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR5AQGg_laPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}